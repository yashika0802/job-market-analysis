{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf98aefb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1122, 15)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "df_DA = pd.read_csv('DataAnalystJobData_scrappeddata.csv')\n",
    "df_JD = pd.read_csv('JobData_scrappeddata.csv')\n",
    "\n",
    "#concatenate\n",
    "df_concatenated = pd.concat([df_DA, df_JD], axis=0)\n",
    "# Reset the index for a continuous index\n",
    "df_concatenated = df_concatenated.reset_index(drop=True)\n",
    "df_concatenated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59e51712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_salary(row):\n",
    "    text = str(row['Benefits'])  # Convert the Benefits column to a string\n",
    "#     print(f\"Processing text: {text}\")  # Debug: print the text being processed\n",
    "    \n",
    "    #Exclude '401K', '401(k)', and standalone '401' by removing these from the text\n",
    "    text = re.sub(r'401[Kk]?(\\(k\\))?', '', text)  # Remove all variations of '401K', '401(k)', and '401'\n",
    "    \n",
    "    #Define regex patterns to match salary ranges and values\n",
    "    patterns = [\n",
    "        r'\\b(?:salary|range|pay|compensation|base)\\b.*?\\$(\\d{1,3}(?:,\\d{3})?)\\s*-\\s*\\$(\\d{1,3}(?:,\\d{3})?)',  # Range with $ and salary-related keywords\n",
    "        r'\\b(?:salary|pay|compensation|base)\\b.*?\\$(\\d{1,3})[Kk]',  # Single value with 'K'\n",
    "        r'\\b(?:salary|pay|compensation|base)\\b.*?(\\d{1,3})[Kk]',  # Single value without '$' but with 'K'\n",
    "        r'\\$(\\d{1,3}(?:,\\d{3})*)',  # Single value with $\n",
    "        r'(\\d{1,3}(?:,\\d{3})*)',  # Single value without $\n",
    "    ]\n",
    "    \n",
    "    salary_values = []  # List to store extracted salary values\n",
    "\n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, text, re.IGNORECASE)  # Find all matches for the current pattern\n",
    "#         print(f\"Matches for pattern '{pattern}': {matches}\")  # Debug: print matches for each pattern\n",
    "        \n",
    "        for match in matches:\n",
    "            if isinstance(match, tuple):  # Handle ranges\n",
    "                low, high = match\n",
    "                low = low.replace(',', '')\n",
    "                high = high.replace(',', '')\n",
    "                \n",
    "                # Check if 'K' is present and multiply by 1,000 if necessary\n",
    "                low_value = float(low) * 1000 if 'K' in text else float(low)\n",
    "                high_value = float(high) * 1000 if 'K' in text else float(high)\n",
    "                \n",
    "                # Calculate the average of the range\n",
    "                salary_range_mean = (low_value + high_value) / 2\n",
    "                salary_values.append(salary_range_mean)\n",
    "#                 print(f\"Range found: {match}, Mean: {salary_range_mean}\")  # Debug: print the range and mean value\n",
    "                \n",
    "            else:  # Handle single values\n",
    "                match = match.replace(',', '')  # Remove commas\n",
    "                \n",
    "                # If 'K' is present immediately after the number, multiply by 1,000\n",
    "                if 'K' in text:\n",
    "                    salary_value = float(match) * 1000\n",
    "                else:\n",
    "                    salary_value = float(match)\n",
    "\n",
    "                salary_values.append(salary_value)  # Add the single value to the list\n",
    "#                 print(f\"Single value found: {match}, Converted: {salary_value}\")  # Debug: print the found single value\n",
    "\n",
    "    # Get the largest salary from the collected values\n",
    "    if salary_values:\n",
    "        max_salary = max(salary_values)\n",
    "#         print(f\"Max salary found: {max_salary}\")  # Debug: print the max salary found\n",
    "        return max_salary  # Return the maximum salary found\n",
    "\n",
    "    return None  # If no salaries were found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c1af76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_salary_range(text):\n",
    "    # Convert the input to a string and strip any surrounding spaces\n",
    "    text = str(text).strip()\n",
    "#     print(f\"Processing text: {text}\")  # Debugging output to show what we're processing\n",
    "    \n",
    "    # Match any number with optional commas and optional decimals\n",
    "    if re.match(r'\\d+', text):\n",
    "        try:\n",
    "            salary_value = float(text)  # Try to convert the string to a float\n",
    "            annual_salary = annual_salary_cal(salary_value)\n",
    "            return annual_salary\n",
    "        except ValueError:\n",
    "            #Replace the special character 'â€“' with a standard dash '-'\n",
    "            text = text.replace('â€“', '-').replace('–', '-')  # Replace all special dashes\n",
    "\n",
    "            # Handle salary ranges and single values\n",
    "            range_pattern = r'\\$?(\\d{1,3}(?:,\\d{3})?(?:[Kk])?)\\s*-\\s*\\$?(\\d{1,3}(?:,\\d{3})?(?:[Kk])?)'\n",
    "            single_value_pattern = r'\\$?(\\d{1,3}(?:,\\d{3})?(?:\\.\\d{1,2})?(?:[Kk])?)'\n",
    "\n",
    "            match_range = re.search(range_pattern, text)\n",
    "            match_single = re.search(single_value_pattern, text)\n",
    "\n",
    "            #If it's a range, process and calculate the mean\n",
    "            if match_range:\n",
    "                low, high = match_range.groups()\n",
    "                low = low.replace(',', '')\n",
    "                high = high.replace(',', '')\n",
    "\n",
    "                if 'K' in low.upper():\n",
    "                    low = low.replace('K', '000')\n",
    "                if 'K' in high.upper():\n",
    "                    high = high.replace('K', '000')\n",
    "\n",
    "                salary_mean = (float(low) + float(high)) / 2\n",
    "                if 'hour' in text.lower():\n",
    "                    return salary_mean * 40 * 52  # Convert hourly rate to annual\n",
    "                elif 'week' in text.lower():\n",
    "                    return salary_mean * 52  # Convert weekly rate to annual\n",
    "                else:\n",
    "                    return salary_mean  # Return mean for yearly values\n",
    "\n",
    "            #If it's a single value, process it 120K a year\n",
    "            elif match_single:\n",
    "                value = match_single.group(1).replace(',', '')\n",
    "                if 'K' in value.upper():\n",
    "                    value = value.replace('K', '000')\n",
    "\n",
    "                if 'hour' in text.lower():\n",
    "                    return float(value) * 40 * 52  # Convert hourly rate to annual\n",
    "                elif 'week' in text.lower():\n",
    "                    return float(value) * 52  # Convert weekly rate to annual\n",
    "                else:\n",
    "                    return float(value)  # Return the single yearly value as a float\n",
    "\n",
    "            #If no matches, return the original text unchanged\n",
    "            return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e5a0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annual_salary_cal(salary_value):\n",
    "        # Check if salary is between 1 and 200 (hourly rate)\n",
    "        if 1 <= salary_value <= 200:\n",
    "            return salary_value * 40 * 52  # Convert hourly to annual salary\n",
    "        # Check if salary is between 201 and 2,000 (weekly rate)\n",
    "        elif 201 <= salary_value <= 2000:\n",
    "            return salary_value * 52  # Convert weekly to annual salary\n",
    "        # Check if salary is between 2,000 and 8,000 (monthly rate)\n",
    "        elif 2000 <= salary_value <= 8000:\n",
    "            return salary_value * 12  # Convert monthly to annual salary\n",
    "        else:\n",
    "            return salary_value  # Return the salary as it is (annual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f86f61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract skills from the 'Qualifications' column\n",
    "def extract_skills(text, skills):\n",
    "    if pd.isna(text):\n",
    "        return ''\n",
    "    found_skills = [skill for skill in skills if re.search(r'\\b' + re.escape(skill) + r'\\b', text, re.IGNORECASE)]\n",
    "    return ', '.join(found_skills)\n",
    "\n",
    "# Extract years of experience from the 'Qualifications' column\n",
    "def extract_years_of_experience(text):\n",
    "    if pd.isna(text):\n",
    "        return None\n",
    "    \n",
    "    patterns = [\n",
    "        r'(\\d+)\\+?\\s*(?:years?|yrs?)\\s*(?:of)?\\s*(?:experience|exp)',\n",
    "        r'(\\d+)\\+?\\s*(?:years?|yrs?)\\s*(?:of)?\\s*(?:relevant|related)\\s*(?:experience|exp)',\n",
    "        r'(\\d+)-(\\d+)\\s*(?:years?|yrs?)\\s*(?:of)?\\s*(?:experience|exp)',\n",
    "        r'minimum\\s*(?:of)?\\s*(\\d+)\\s*(?:years?|yrs?)\\s*(?:of)?\\s*(?:experience|exp)',\n",
    "        r'at least\\s*(\\d+)\\s*(?:years?|yrs?)',\n",
    "        r'(\\d+)\\+?\\s*(?:years?|yrs?)',\n",
    "        r'(\\d+)\\s*(?:to|–|-)\\s*(\\d+)\\s*(?:years?|yrs?)',\n",
    "        r'(?:bachelor|master|phd).*?(\\d+)\\+?\\s*(?:years?|yrs?)',\n",
    "        r'(\\d+)\\+?\\s*(?:years?|yrs?).*?(?:bachelor|master|phd)'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            return f\"{match.group(1)}-{match.group(2)}\" if len(match.groups()) == 2 else match.group(1)\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93b97098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the DataFrame\n",
    "def process_dataframe(df):\n",
    "    skills = ['Python', 'Hive', 'SQL', 'MySQL', 'Oracle', 'Tableau', 'Snowflake', 'Redshift', 'Big Data', 'Spark', 'AWS', 'GCP', 'Azure', 'Java', 'Cloud', 'Data Analytics', 'Analytics', 'ETL', 'Business Intelligence', 'data warehouse', 'Power BI','Excel', 'Data Visualization', 'Visualization']\n",
    "    df['Education'] = df['Qualifications'].apply(extract_education)\n",
    "    df['Years of Experience Required'] = df['Qualifications'].apply(extract_years_of_experience)\n",
    "    df['Salary_New'] = df['Salary']\n",
    "    mask = df['Salary'].isnull()\n",
    "    df.loc[mask, 'Salary_New'] = df[mask].apply(extract_salary, axis=1)\n",
    "    df.loc[df['Salary_New'].astype(str).str.contains('401', na=False), 'Salary_New'] = None\n",
    "    df['Skills'] = df['Qualifications'].apply(lambda x: extract_skills(x, skills))\n",
    "    # Apply the function to the 'Salary_New' column, skipping rows where the result is None\n",
    "    df['Salary_New_Processed'] = df['Salary_New'].apply(lambda x: process_salary_range(x) if pd.notnull(x) else x)\n",
    "    df['JobTitle_New'] = df['Job title'].apply(job_title_categ)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad2d1272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_education(text):\n",
    "    if pd.isna(text):\n",
    "        return \"Any Degree\"\n",
    "    # Regex pattern for capturing degree keywords (case insensitive)\n",
    "    pattern = r'\\b(PHD|PH\\.D|Post\\s?Grad|Master\\'?s?|Bachelors?\\'?)\\b'\n",
    "        # Search for matching degree keywords in the text\n",
    "    matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "    # Set precedence order\n",
    "    precedence = ['PHD', 'PH.D', 'Post Grad', 'Master', \"Master's\", \"Masters\", 'Bachelor', \"Bachelor's\", \"Bachelors\"] \n",
    "    # If there are matches, return the highest precedence degree\n",
    "    if matches:\n",
    "        # Sort based on the order of precedence\n",
    "        for degree in precedence:\n",
    "            for match in matches:\n",
    "                if re.search(degree, match, re.IGNORECASE):\n",
    "                    if degree.lower().startswith(\"p\"):\n",
    "                        return f\"PHD\"\n",
    "                    if degree.lower().startswith(\"b\"):\n",
    "                        return f\"Bachelors\"\n",
    "                    if degree.lower().startswith(\"m\"):\n",
    "                        return f\"Masters\"\n",
    "                    return degree  # Return the first match based on precedence\n",
    "    # If no match found, return \"Any Degree\"\n",
    "    return f\"Any Degree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae6c871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job_title_categ(title):\n",
    "    if isinstance(title, str):  # Check if the title is a string\n",
    "        title = title.lower()  # Convert to lowercase for uniformity\n",
    "        \n",
    "        # Check for Data Engineer roles (allowing any number of words between 'data' and 'engineer')\n",
    "        if re.search(r'data.*engineer', title):\n",
    "            return 'Data Engineer'\n",
    "        \n",
    "        # Check for Data Scientist roles (allowing any number of words between 'data' and 'science/scientist')\n",
    "        elif re.search(r'data.*(science|scientist)', title):\n",
    "            return 'Data Scientist'\n",
    "        \n",
    "        # Check for Business Analyst roles\n",
    "        elif re.search(r'business.*analyst', title):\n",
    "            return 'Business Analyst'\n",
    "        \n",
    "        # Check for Business Intelligence Analyst roles (allowing any number of words between 'business' and 'intelligence')\n",
    "        elif re.search(r'business.*intelligence', title):\n",
    "            return 'Business Intelligence Analyst'\n",
    "        \n",
    "        # Check for Data Analyst roles (matching data with analytics/analysis)\n",
    "        elif re.search(r'data.*(analytics|analysis|analyst)', title):\n",
    "            return 'Data Analyst'\n",
    "        \n",
    "        else:\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f1c4868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 URL     Job title  \\\n",
      "0  https://www.google.com/search?q=data+analyst+j...  Data Analyst   \n",
      "1  https://www.google.com/search?q=data+analyst+j...  Data Analyst   \n",
      "\n",
      "                                    Job sub-headings               Company  \\\n",
      "0  Disney Entertainment • Santa Monica, CA •  via...  Disney Entertainment   \n",
      "1         Tax Rise • Newport Beach, CA •  via Adzuna              Tax Rise   \n",
      "\n",
      "            Location          Source        Posted       Type  \\\n",
      "0   Santa Monica, CA  Disney Careers   14 days ago  Full-time   \n",
      "1  Newport Beach, CA          Adzuna  19 hours ago  Full-time   \n",
      "\n",
      "                                 Job additional data  \\\n",
      "0   ['14 days ago', 'Full-time', 'Health insurance']   \n",
      "1  ['19 hours ago', '80K–95K a year', 'Full-time'...   \n",
      "\n",
      "                                     Job Description  ...  \\\n",
      "0  About the Role & TeamWe’re looking for an inte...  ...   \n",
      "1  INTRO TO TAXRISE:At TaxRise, our mission is si...  ...   \n",
      "\n",
      "                                            Benefits  \\\n",
      "0  The hiring range for this position in CA is $9...   \n",
      "1  Medical, Dental, and Vision Insurance after 60...   \n",
      "\n",
      "                                    Responsibilities          Salary  \\\n",
      "0  In this role, you will be responsible for driv...             NaN   \n",
      "1  As the Data Analyst, you will need to be organ...  80K–95K a year   \n",
      "\n",
      "  No Degree Mentioned   Education Years of Experience Required  \\\n",
      "0                 NaN  Any Degree                            3   \n",
      "1                 NaN  Any Degree                            2   \n",
      "\n",
      "       Salary_New                Skills Salary_New_Processed  JobTitle_New  \n",
      "0        125200.0                   SQL             125200.0  Data Analyst  \n",
      "1  80K–95K a year  SQL, Azure, Power BI              87500.0  Data Analyst  \n",
      "\n",
      "[2 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "df_textcleaned = process_dataframe(df_concatenated)\n",
    "print(df_textcleaned.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50019018-a1f5-4ed3-bdfb-d66bef9c56ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Company           Location          Source       Type  \\\n",
      "0  Disney Entertainment   Santa Monica, CA  Disney Careers  Full-time   \n",
      "1              Tax Rise  Newport Beach, CA          Adzuna  Full-time   \n",
      "\n",
      "    Education Years of Experience Required                Skills  \\\n",
      "0  Any Degree                            3                   SQL   \n",
      "1  Any Degree                            2  SQL, Azure, Power BI   \n",
      "\n",
      "   Salary_New_Processed  JobTitle_New  \n",
      "0              125200.0  Data Analyst  \n",
      "1               87500.0  Data Analyst  \n"
     ]
    }
   ],
   "source": [
    "#Dropping the unnecessary columns from Data Analyst job data\n",
    "df_textcleaned = df_textcleaned.drop(['URL','Job title','Job sub-headings','Posted','Job additional data','Job Description', \n",
    "                               'Qualifications','Benefits','Responsibilities','Salary','No Degree Mentioned', 'Salary_New'], axis=1)\n",
    "print(df_textcleaned.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76f470ac-b4ba-4556-b049-85a8d5be7611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Company Location          Source       Type   Education  \\\n",
      "0  Disney Entertainment       CA  Disney Careers  Full-time  Any Degree   \n",
      "1              Tax Rise       CA          Adzuna  Full-time  Any Degree   \n",
      "\n",
      "  Years of Experience Required                Skills  Salary_New_Processed  \\\n",
      "0                            3                   SQL              125200.0   \n",
      "1                            2  SQL, Azure, Power BI               87500.0   \n",
      "\n",
      "   JobTitle_New  \n",
      "0  Data Analyst  \n",
      "1  Data Analyst  \n"
     ]
    }
   ],
   "source": [
    "#converting the full state names and city names to two-letter Shortforms\n",
    "def clean_location(location):\n",
    "    # Mapping of full state names and specific locations to abbreviations\n",
    "    state_mapping = {\n",
    "        'California': 'CA',\n",
    "        'New York': 'NY',\n",
    "        'Texas': 'TX',\n",
    "        'Washington': 'WA',\n",
    "        'Florida': 'FL',\n",
    "        'Massachusetts': 'MA',\n",
    "        'Illinois': 'IL',\n",
    "        'United States': 'USA',\n",
    "        'Pennsylvania': 'PA',\n",
    "        'Nevada': 'NV',\n",
    "        'Alabama':'AL',\n",
    "        'Michigan':'MI' ,\n",
    "        'Fort Lewis':'WA',\n",
    "        'Georgia':'GA',\n",
    "        'Arizona':'AZ' ,\n",
    "        'Illnois':'IL',\n",
    "        'Connecticut':'CT',\n",
    "        'Minnesota':'MN',\n",
    "        'Kentucky':'KY',\n",
    "        'North Carolina': 'NC',\n",
    "        'New Jersey': 'NJ'\n",
    "    }\n",
    "    \n",
    "    # Check if the location is a string\n",
    "    if isinstance(location, str):\n",
    "        # Split the location string and check for abbreviations or full names\n",
    "        parts = location.split(', ')\n",
    "        if len(parts) > 1:\n",
    "            # Check if the last part is an abbreviation or full state name\n",
    "            state_abbr = parts[-1].strip()\n",
    "            return state_mapping.get(state_abbr, state_abbr)  # Return abbreviation if found\n",
    "        else:\n",
    "            # Attempt to map full state names to abbreviations\n",
    "            return state_mapping.get(location.strip(), location.strip())  # Return original if no match\n",
    "    else:\n",
    "        return pd.NA  # Return NA for non-string values\n",
    "\n",
    "# Clean the 'Location' column\n",
    "df_textcleaned['Location'] = df_textcleaned['Location'].apply(clean_location)\n",
    "# Display the first few rows of the cleaned DataFrame\n",
    "print(df_textcleaned.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5cc448a-d178-4afa-aca3-d5298407ac92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type\n",
      "Full-time     905\n",
      "Part-time     178\n",
      "Internship     15\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Changing the combination of Full-Time, Part-time and Contractor Positions to Part-time and \n",
    "#Part-time and Contractor to Part-time and Full-time and Internship to Internship\n",
    "def clean_type(job_type):\n",
    "    if pd.isna(job_type):\n",
    "        return job_type  \n",
    "\n",
    "    job_type = job_type.lower()  # Convert to lowercase for consistent comparisons\n",
    "    \n",
    "    # Apply the transformation rules\n",
    "    if 'internship' in job_type:\n",
    "        return 'Internship'\n",
    "    elif 'part-time' in job_type or 'contractor' in job_type:\n",
    "        return 'Part-time'\n",
    "    elif 'full-time' in job_type:\n",
    "        return 'Full-time'\n",
    "    else:\n",
    "        return job_type  # Return the original job_type if it doesn't match any condition\n",
    "\n",
    "# Apply the clean_type function to the 'Type' column\n",
    "df_textcleaned['Type'] = df_textcleaned['Type'].apply(clean_type)\n",
    "\n",
    "# Print a summary of the cleaned 'Type' column\n",
    "print(df_textcleaned['Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa111d03-3fa4-4fce-88c9-04db4808f521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Salaries by Job Title:\n",
      "JobTitle_New\n",
      "Business Analyst                  91520.0\n",
      "Business Intelligence Analyst    158230.0\n",
      "Data Analyst                     100000.0\n",
      "Data Engineer                    166000.0\n",
      "Data Scientist                   195000.0\n",
      "Name: Salary_New_Processed, dtype: float64\n",
      "\n",
      "Number of missing salaries after filling: 79\n"
     ]
    }
   ],
   "source": [
    "#Applying median Values to Missing and Nan salaries as per JobTitle_New\n",
    "def calculate_median_salaries(df):\n",
    "       return df.groupby('JobTitle_New')['Salary_New_Processed'].median()\n",
    "\n",
    "def fill_missing_salaries(df, median_salaries):\n",
    "    def fill_salary(row):\n",
    "        if pd.isna(row['Salary_New_Processed']):\n",
    "            return median_salaries.get(row['JobTitle_New'], np.nan)\n",
    "        return row['Salary_New_Processed']  \n",
    "    \n",
    "    df['Salary_New_Processed'] = df.apply(fill_salary, axis=1)\n",
    "    return df\n",
    "\n",
    "# Calculate median salaries\n",
    "median_salaries = calculate_median_salaries(df_textcleaned)\n",
    "    \n",
    "# Fill missing salaries\n",
    "df_textcleaned = fill_missing_salaries(df_textcleaned, median_salaries)\n",
    "    \n",
    "# Print summary\n",
    "print(\"Median Salaries by Job Title:\")\n",
    "print(median_salaries)\n",
    "print(\"\\nNumber of missing salaries after filling:\", df_textcleaned['Salary_New_Processed'].isna().sum()) #the rows without job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12a37d2b-81f4-41ff-9fec-42d2c277dc36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "count    1.043000e+03\n",
      "mean     6.472463e+05\n",
      "std      9.783008e+06\n",
      "min      2.080000e+03\n",
      "25%      9.152000e+04\n",
      "50%      1.000000e+05\n",
      "75%      1.660000e+05\n",
      "max      2.158000e+08\n",
      "Name: Salary_New_Processed, dtype: float64\n",
      "Original number of rows: 1122\n",
      "\n",
      "Cleaned DataFrame:\n",
      "count       999.000000\n",
      "mean     123914.412412\n",
      "std       60404.855389\n",
      "min        2080.000000\n",
      "25%       91520.000000\n",
      "50%      100000.000000\n",
      "75%      166000.000000\n",
      "max      416000.000000\n",
      "Name: Salary_New_Processed, dtype: float64\n",
      "Cleaned number of rows: 999\n",
      "\n",
      "Total number of rows removed: 123\n",
      "Number of rows removed due to no job type but with salary: 39\n"
     ]
    }
   ],
   "source": [
    "#removing Outliers and rows with no job type but with salary\n",
    "\n",
    "def remove_salary_outliers_and_no_jobtype(df, salary_column, job_column, max_limit):\n",
    "    # Create a copy of the DataFrame to avoid modifying the original\n",
    "    df_cleaned = df.copy()\n",
    "    \n",
    "    # Remove outliers\n",
    "    df_cleaned = df_cleaned[df_cleaned[salary_column] <= max_limit]\n",
    "    \n",
    "    # Remove rows with no job type but with salary value\n",
    "    df_cleaned = df_cleaned[~((df_cleaned[job_column].isna() | (df_cleaned[job_column] == '')) & df_cleaned[salary_column].notna())]\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "# Apply the function to remove outliers and rows with no job type but with salary\n",
    "max_salary_limit = 600000\n",
    "df_cleaned = remove_salary_outliers_and_no_jobtype(df_textcleaned, 'Salary_New_Processed', 'JobTitle_New', max_salary_limit)\n",
    "\n",
    "# Print summary statistics to verify the changes\n",
    "print(\"Original DataFrame:\")\n",
    "print(df_textcleaned['Salary_New_Processed'].describe())\n",
    "print(f\"Original number of rows: {len(df_textcleaned)}\")\n",
    "\n",
    "print(\"\\nCleaned DataFrame:\")\n",
    "print(df_cleaned['Salary_New_Processed'].describe())\n",
    "print(f\"Cleaned number of rows: {len(df_cleaned)}\")\n",
    "\n",
    "# Print the number of rows removed\n",
    "rows_removed = len(df_textcleaned) - len(df_cleaned)\n",
    "print(f\"\\nTotal number of rows removed: {rows_removed}\")\n",
    "\n",
    "# Print the number of rows removed due to no job type but with salary\n",
    "rows_removed_no_jobtype = len(df_textcleaned[((df_textcleaned['JobTitle_New'].isna() | (df_textcleaned['JobTitle_New'] == '')) & df_textcleaned['Salary_New_Processed'].notna())])\n",
    "print(f\"Number of rows removed due to no job type but with salary: {rows_removed_no_jobtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cebdb8f-563f-46b1-84ba-3d027b5d618c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of Years of Experience Required by Type:\n",
      "            count  unique  top   freq\n",
      "Type                                 \n",
      "Full-time   816.0    18.0  5.0  349.0\n",
      "Internship   14.0     3.0  0.0   11.0\n",
      "Part-time   164.0    12.0  5.0   76.0\n",
      "\n",
      "Sample of updated data:\n",
      "           Type Years of Experience Required\n",
      "579   Full-time                           10\n",
      "1027  Full-time                          5.0\n",
      "325   Full-time                          5.0\n",
      "281   Full-time                          5.0\n",
      "550   Full-time                          5.0\n",
      "1104  Full-time                            8\n",
      "494   Part-time                          5.0\n",
      "742   Full-time                            4\n",
      "369   Full-time                          5.0\n",
      "904   Part-time                            5\n"
     ]
    }
   ],
   "source": [
    "def calculate_median_experience(df):\n",
    "    full_time_median = df[df['Type'] == 'Full-time']['Years of Experience Required'].median()\n",
    "    part_time_median = df[df['Type'] == 'Part-time']['Years of Experience Required'].median()\n",
    "    return full_time_median, part_time_median\n",
    "\n",
    "def update_experience_required(row, full_time_median, part_time_median):\n",
    "    if pd.isna(row['Years of Experience Required']):\n",
    "        if row['Type'] == 'Full-time':\n",
    "            return full_time_median\n",
    "        elif row['Type'] == 'Part-time':\n",
    "            return part_time_median\n",
    "        elif row['Type'] == 'Internship':\n",
    "            return 0\n",
    "    return row['Years of Experience Required']\n",
    "\n",
    "def clean_data(df):\n",
    "    full_time_median, part_time_median = calculate_median_experience(df)\n",
    "    \n",
    "    df['Years of Experience Required'] = df.apply(\n",
    "        lambda row: update_experience_required(row, full_time_median, part_time_median), \n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_cleaned = clean_data(df_cleaned)  \n",
    "\n",
    "print(\"Summary of Years of Experience Required by Type:\")\n",
    "print(df_cleaned.groupby('Type')['Years of Experience Required'].describe())\n",
    "    \n",
    "print(\"\\nSample of updated data:\")\n",
    "print(df_cleaned[['Type', 'Years of Experience Required']].sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0868f22a-915b-4e8b-a179-c62ec8135ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of cleaned Source column:\n",
      "Source\n",
      "Company Website    503\n",
      "LinkedIn           300\n",
      "ZipRecruiter       110\n",
      "Glassdoor           50\n",
      "Indeed              36\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sample of cleaned Source data:\n",
      "               Source\n",
      "642   Company Website\n",
      "331          LinkedIn\n",
      "330          LinkedIn\n",
      "851   Company Website\n",
      "797          LinkedIn\n",
      "1009  Company Website\n",
      "1054           Indeed\n",
      "197   Company Website\n",
      "387   Company Website\n",
      "907   Company Website\n"
     ]
    }
   ],
   "source": [
    "#Converting all the job sources to company websites other than LinkedIn, Indeed, ZipRecruiter, Glassdoor\n",
    "def clean_source(Source):\n",
    "    \n",
    "    allowed_sources = [\"LinkedIn\", \"Indeed\", \"ZipRecruiter\", \"Glassdoor\"]\n",
    "    if Source in allowed_sources:\n",
    "        return Source\n",
    "    else:\n",
    "        return \"Company Website\"\n",
    "\n",
    "def apply_cleaning_to_source_column(df):\n",
    "    \n",
    "    df['Source'] = df['Source'].apply(clean_source)\n",
    "    return df\n",
    " \n",
    "# Apply cleaning to the Source column\n",
    "df_cleaned = apply_cleaning_to_source_column(df_cleaned)\n",
    "    \n",
    "# Print summary of the cleaned Source column\n",
    "print(\"Summary of cleaned Source column:\")\n",
    "print(df_cleaned['Source'].value_counts())\n",
    "    \n",
    "# Print a sample of the cleaned data\n",
    "print(\"\\nSample of cleaned Source data:\")\n",
    "print(df_cleaned[['Source']].sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b321c71-ef87-4c52-a018-290539385b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 9)\n",
      "                Company Location           Source       Type   Education  \\\n",
      "0  Disney Entertainment       CA  Company Website  Full-time  Any Degree   \n",
      "1              Tax Rise       CA  Company Website  Full-time  Any Degree   \n",
      "2               PragerU       CA         LinkedIn  Full-time  Any Degree   \n",
      "3  Disney Entertainment       CA  Company Website  Full-time  Any Degree   \n",
      "4  Keck Medicine of USC       CA  Company Website  Full-time   Bachelors   \n",
      "\n",
      "  Years of Experience Required  \\\n",
      "0                            3   \n",
      "1                            2   \n",
      "2                            4   \n",
      "3                            3   \n",
      "4                            4   \n",
      "\n",
      "                                              Skills  Salary_New_Processed  \\\n",
      "0                                                SQL              125200.0   \n",
      "1                               SQL, Azure, Power BI               87500.0   \n",
      "2  Python, SQL, Analytics, Business Intelligence,...              150000.0   \n",
      "3                                                SQL              125200.0   \n",
      "4                                           SQL, ETL              158230.0   \n",
      "\n",
      "                    JobTitle_New  \n",
      "0                   Data Analyst  \n",
      "1                   Data Analyst  \n",
      "2                  Data Engineer  \n",
      "3                   Data Analyst  \n",
      "4  Business Intelligence Analyst  \n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned DataFrame back to a CSV file\n",
    "df_cleaned.to_csv('JobData_Cleaned.csv', index=False)\n",
    "\n",
    "#final clened data frame\n",
    "JobData_df = df_cleaned\n",
    "\n",
    "# Determine dimensions of dataframe. \n",
    "print(JobData_df.shape) # It has 999rows and 9 columns\n",
    "print(JobData_df.head(5))#First 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c34b5edb-af47-41ea-8c07-e62995034d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Updated DataFrame with both Location and Source dummy variables:\n",
      "                Company Years of Experience Required  \\\n",
      "0  Disney Entertainment                            3   \n",
      "1              Tax Rise                            2   \n",
      "2               PragerU                            4   \n",
      "3  Disney Entertainment                            3   \n",
      "4  Keck Medicine of USC                            4   \n",
      "\n",
      "                                              Skills  Salary_New_Processed  \\\n",
      "0                                                SQL              125200.0   \n",
      "1                               SQL, Azure, Power BI               87500.0   \n",
      "2  Python, SQL, Analytics, Business Intelligence,...              150000.0   \n",
      "3                                                SQL              125200.0   \n",
      "4                                           SQL, ETL              158230.0   \n",
      "\n",
      "   Location_AL  Location_AR  Location_AZ  Location_CA  Location_CO  \\\n",
      "0            0            0            0            1            0   \n",
      "1            0            0            0            1            0   \n",
      "2            0            0            0            1            0   \n",
      "3            0            0            0            1            0   \n",
      "4            0            0            0            1            0   \n",
      "\n",
      "   Location_CT  ...  Type_Part-time  Education_Any Degree  \\\n",
      "0            0  ...               0                     1   \n",
      "1            0  ...               0                     1   \n",
      "2            0  ...               0                     1   \n",
      "3            0  ...               0                     1   \n",
      "4            0  ...               0                     0   \n",
      "\n",
      "   Education_Bachelors  Education_Masters  Education_PHD  \\\n",
      "0                    0                  0              0   \n",
      "1                    0                  0              0   \n",
      "2                    0                  0              0   \n",
      "3                    0                  0              0   \n",
      "4                    1                  0              0   \n",
      "\n",
      "   JobTitle_New_Business Analyst  JobTitle_New_Business Intelligence Analyst  \\\n",
      "0                              0                                           0   \n",
      "1                              0                                           0   \n",
      "2                              0                                           0   \n",
      "3                              0                                           0   \n",
      "4                              0                                           1   \n",
      "\n",
      "   JobTitle_New_Data Analyst  JobTitle_New_Data Engineer  \\\n",
      "0                          1                           0   \n",
      "1                          1                           0   \n",
      "2                          0                           1   \n",
      "3                          1                           0   \n",
      "4                          0                           0   \n",
      "\n",
      "   JobTitle_New_Data Scientist  \n",
      "0                            0  \n",
      "1                            0  \n",
      "2                            0  \n",
      "3                            0  \n",
      "4                            0  \n",
      "\n",
      "[5 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create dummy variables for the 'Location' column\n",
    "location_dummies = pd.get_dummies(JobData_df['Location'], prefix='Location', dtype=int)\n",
    "# Create dummy variables for the 'Source' column\n",
    "source_dummies = pd.get_dummies(JobData_df['Source'], prefix='Source', dtype=int)\n",
    "# Create dummy variables for the 'Location' column\n",
    "type_dummies=pd.get_dummies(JobData_df['Type'], prefix='Type', dtype=int)\n",
    "# Create dummy variables for the 'Location' column\n",
    "education_dummies = pd.get_dummies(JobData_df['Education'],prefix='Education',dtype = int)\n",
    "# Create dummy variables for the 'Location' column\n",
    "jobtitle_dummies = pd.get_dummies(JobData_df['JobTitle_New'],prefix='JobTitle_New',dtype = int)\n",
    "# Combine the original data frame with both sets of dummy variables\n",
    "JobData_with_dummies = pd.concat([\n",
    "    JobData_df.drop(['Location', 'Source','Type','Education','JobTitle_New'], axis=1),\n",
    "    location_dummies,\n",
    "    source_dummies,\n",
    "    type_dummies,\n",
    "    education_dummies,\n",
    "    jobtitle_dummies\n",
    "], axis=1)\n",
    "\n",
    "# Display the first few rows of the updated DataFrame\n",
    "print(\"\\nUpdated DataFrame with both Location and Source dummy variables:\")\n",
    "print(JobData_with_dummies.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39b72908-56f0-48ad-98b1-c4092bff06f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Company', 'Years_of_Experience_Required', 'Skills',\n",
      "       'Salary_New_Processed', 'Location_AL', 'Location_AR', 'Location_AZ',\n",
      "       'Location_CA', 'Location_CO', 'Location_CT', 'Location_DC',\n",
      "       'Location_DE', 'Location_FL', 'Location_GA', 'Location_IA',\n",
      "       'Location_ID', 'Location_IL', 'Location_IN', 'Location_KS',\n",
      "       'Location_KY', 'Location_LA', 'Location_MA', 'Location_MD',\n",
      "       'Location_MI', 'Location_MN', 'Location_MO', 'Location_MS',\n",
      "       'Location_MT', 'Location_NC', 'Location_ND', 'Location_NE',\n",
      "       'Location_NH', 'Location_NJ', 'Location_NM', 'Location_NV',\n",
      "       'Location_NY', 'Location_OH', 'Location_OK', 'Location_OR',\n",
      "       'Location_PA', 'Location_RI', 'Location_SC', 'Location_SD',\n",
      "       'Location_TN', 'Location_TX', 'Location_USA', 'Location_UT',\n",
      "       'Location_VA', 'Location_WA', 'Location_WI', 'Location_WV',\n",
      "       'Source_Company_Website', 'Source_Glassdoor', 'Source_Indeed',\n",
      "       'Source_LinkedIn', 'Source_ZipRecruiter', 'Type_Full_time',\n",
      "       'Type_Internship', 'Type_Part_time', 'Education_Any_Degree',\n",
      "       'Education_Bachelors', 'Education_Masters', 'Education_PHD',\n",
      "       'JobTitle_New_Business_Analyst',\n",
      "       'JobTitle_New_Business_Intelligence_Analyst',\n",
      "       'JobTitle_New_Data_Analyst', 'JobTitle_New_Data_Engineer',\n",
      "       'JobTitle_New_Data_Scientist'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Create dummy variables\n",
    "# Replace spaces with underscores in column names\n",
    "JobData_with_dummies.columns = JobData_with_dummies.columns.str.replace(' ', '_')\n",
    "JobData_with_dummies.columns = JobData_with_dummies.columns.str.replace('-', '_')\n",
    "\n",
    "# Display the data types\n",
    "print(JobData_with_dummies.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c07644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
